{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Intelligent document processing\n",
        "\n",
        "Helps in processign unstructured and semi-structured data in documents."
      ],
      "metadata": {
        "id": "-CSDkcmvSSMl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Only for the 20pdf"
      ],
      "metadata": {
        "id": "PWnaUa6cq2I1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "pdf_path = kagglehub.dataset_download(\"snehaanbhawal/resume-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", pdf_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZtus-8ilc83",
        "outputId": "2dabe3df-0ddc-460a-a2c4-facb99731116"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'resume-dataset' dataset.\n",
            "Path to dataset files: /kaggle/input/resume-dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installations and processing functions:"
      ],
      "metadata": {
        "id": "YitMhpPbzXtP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0HEZWYgdR4Xb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fb11574-ddab-474d-bb35-5bcfc318aa10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "poppler-utils is already the newest version (22.02.0-2ubuntu0.10).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 38 not upgraded.\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pdf2image in /usr/local/lib/python3.12/dist-packages (1.17.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: poppler-utils in /usr/local/lib/python3.12/dist-packages (0.1.0)\n",
            "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.12/dist-packages (from poppler-utils) (8.2.1)\n",
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.12/dist-packages (from pytesseract) (25.0)\n"
          ]
        }
      ],
      "source": [
        "!sudo apt-get install -y poppler-utils\n",
        "\n",
        "! pip install opencv-python matplotlib numpy pdf2image\n",
        "! pip install poppler-utils\n",
        "! pip install pytesseract pillow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "irziWzNQvXpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_image(image, title=\"Image\"):\n",
        "    plt.figure(figsize=(7, 7))\n",
        "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "    plt.title(title)\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "yU6NIO5Fvi5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the image to grayscale\n",
        "def convert_to_grayscale(image):\n",
        "  return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "def reduce_noise(gray_image):\n",
        "  return cv2.GaussianBlur(gray_image, (5, 5), 0)"
      ],
      "metadata": {
        "id": "5v6jXn-cv1p1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def binarize_image(blur_reduced_image):\n",
        "  return cv2.adaptiveThreshold(\n",
        "    blur_reduced_image,\n",
        "    255,\n",
        "    cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
        "    cv2.THRESH_BINARY_INV, # Invert the colors (text becomes white)\n",
        "    11, # Block size\n",
        "    4  # Constant C\n",
        "  )"
      ],
      "metadata": {
        "id": "rgtpAOIFv3uI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def deskew_image(image):\n",
        "    \"\"\"\n",
        "    Corrects the skew of an image by finding the minimum area rectangle\n",
        "    of the text block and rotating accordingly.\n",
        "    \"\"\"\n",
        "    # Find all non-zero (white) pixels\n",
        "    coords = cv2.findNonZero(image)\n",
        "\n",
        "    # Get the minimum area bounding rectangle\n",
        "    # It returns (center(x,y), (width, height), angle of rotation)\n",
        "    rect = cv2.minAreaRect(coords)\n",
        "    angle = rect[-1] - 90\n",
        "\n",
        "    # The `cv2.minAreaRect` angle has a specific range.\n",
        "    # We need to adjust it for our rotation.\n",
        "    if angle < -45:\n",
        "        angle = -(90 + angle)\n",
        "    else:\n",
        "        angle = angle\n",
        "\n",
        "    # Get the rotation matrix and rotate the image\n",
        "    (h, w) = image.shape[:2]\n",
        "    center = (w // 2, h // 2)\n",
        "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
        "    rotated = cv2.warpAffine(image, M, (w, h),\n",
        "                             flags=cv2.INTER_CUBIC,\n",
        "                             borderMode=cv2.BORDER_REPLICATE)\n",
        "    print(f\"Detected skew angle: {angle:.2f} degrees\")\n",
        "\n",
        "    # Now, rotate the original grayscale image by the same angle\n",
        "    (h, w) = rotated.shape\n",
        "    center = (w // 2, h // 2)\n",
        "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
        "    deskewed_gray = cv2.warpAffine(rotated, M, (w, h),\n",
        "                                  flags=cv2.INTER_CUBIC,\n",
        "                                  borderMode=cv2.BORDER_REPLICATE)\n",
        "\n",
        "    return deskewed_gray"
      ],
      "metadata": {
        "id": "a_0OWuTLv5wg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_one_image(image):\n",
        "  image = convert_to_grayscale(image)\n",
        "  print(\"Converted image to grayscale..\")\n",
        "  image = reduce_noise(image)\n",
        "  print(\"Reduced noise in the image..\")\n",
        "  image = binarize_image(image)\n",
        "  print(\"Binarized the image..\")\n",
        "  image = deskew_image(image)\n",
        "  print(\"Corrected image orientation..\")\n",
        "  return image"
      ],
      "metadata": {
        "id": "EcHux5Fgv6k3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepping the resumes for extraction:"
      ],
      "metadata": {
        "id": "uyLbWt9UwG8S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import os\n",
        "import zipfile\n",
        "from pdf2image import convert_from_path\n",
        "\n",
        "output_folder_path = \"/content/processed_images\"\n",
        "\n",
        "if os.makedirs(output_folder_path, exist_ok=True):\n",
        "  print(f\"Created folder: {output_folder_path}\")\n",
        "\n",
        "resumes_folder =\"/kaggle/input/resume-dataset/data/data/ENGINEERING\"\n",
        "\n",
        "for i, resume_name in enumerate(os.listdir(resumes_folder), start=1):\n",
        "  if resume_name.endswith('.pdf'):\n",
        "    print(f\"Processing resume: {resume_name}\")\n",
        "    resume_path = os.path.join(resumes_folder, resume_name)\n",
        "\n",
        "    # Convert the first page of the PDF to an image\n",
        "    try:\n",
        "      pages = convert_from_path(resume_path, first_page=1, last_page=1)\n",
        "      if pages:\n",
        "        image = cv2.cvtColor(np.array(pages[0]), cv2.COLOR_RGB2BGR)\n",
        "        processed_image = process_one_image(image)\n",
        "        output_path = os.path.join(output_folder_path, resume_name.replace('.pdf', '.png'))\n",
        "        cv2.imwrite(output_path, processed_image)\n",
        "        print(f\"Saved processed image to: {output_path}\")\n",
        "        print(\"-\"*50)\n",
        "      else:\n",
        "        print(f\"Could not convert the first page of {resume_name} to an image.\")\n",
        "        print(\"-\"*50)\n",
        "    except Exception as e:\n",
        "      print(f\"Error processing {resume_name}: {e}\")\n",
        "      print(\"-\"*50)\n",
        "\n",
        "    if i >= 20: # stop after 20 files\n",
        "      break\n",
        "\n",
        "\n",
        "print(\"Processing images is completed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLW65XkMwMpH",
        "outputId": "25edba1d-9fac-4271-d820-124353d92814"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing resume: 19124258.pdf\n",
            "Converted image to grayscale..\n",
            "Reduced noise in the image..\n",
            "Binarized the image..\n",
            "Detected skew angle: -0.07 degrees\n",
            "Corrected image orientation..\n",
            "Saved processed image to: /content/processed_images/19124258.png\n",
            "--------------------------------------------------\n",
            "Processing resume: 14206561.pdf\n",
            "Converted image to grayscale..\n",
            "Reduced noise in the image..\n",
            "Binarized the image..\n",
            "Detected skew angle: -0.00 degrees\n",
            "Corrected image orientation..\n",
            "Saved processed image to: /content/processed_images/14206561.png\n",
            "--------------------------------------------------\n",
            "Processing resume: 11890896.pdf\n",
            "Converted image to grayscale..\n",
            "Reduced noise in the image..\n",
            "Binarized the image..\n",
            "Detected skew angle: -0.04 degrees\n",
            "Corrected image orientation..\n",
            "Saved processed image to: /content/processed_images/11890896.png\n",
            "--------------------------------------------------\n",
            "Processing resume: 21629057.pdf\n",
            "Converted image to grayscale..\n",
            "Reduced noise in the image..\n",
            "Binarized the image..\n",
            "Detected skew angle: -0.03 degrees\n",
            "Corrected image orientation..\n",
            "Saved processed image to: /content/processed_images/21629057.png\n",
            "--------------------------------------------------\n",
            "Processing resume: 28320387.pdf\n",
            "Converted image to grayscale..\n",
            "Reduced noise in the image..\n",
            "Binarized the image..\n",
            "Detected skew angle: -0.03 degrees\n",
            "Corrected image orientation..\n",
            "Saved processed image to: /content/processed_images/28320387.png\n",
            "--------------------------------------------------\n",
            "Processing resume: 26456899.pdf\n",
            "Converted image to grayscale..\n",
            "Reduced noise in the image..\n",
            "Binarized the image..\n",
            "Detected skew angle: -0.00 degrees\n",
            "Corrected image orientation..\n",
            "Saved processed image to: /content/processed_images/26456899.png\n",
            "--------------------------------------------------\n",
            "Processing resume: 27152464.pdf\n",
            "Converted image to grayscale..\n",
            "Reduced noise in the image..\n",
            "Binarized the image..\n",
            "Detected skew angle: -0.00 degrees\n",
            "Corrected image orientation..\n",
            "Saved processed image to: /content/processed_images/27152464.png\n",
            "--------------------------------------------------\n",
            "Processing resume: 44624796.pdf\n",
            "Converted image to grayscale..\n",
            "Reduced noise in the image..\n",
            "Binarized the image..\n",
            "Detected skew angle: 0.00 degrees\n",
            "Corrected image orientation..\n",
            "Saved processed image to: /content/processed_images/44624796.png\n",
            "--------------------------------------------------\n",
            "Processing resume: 19396040.pdf\n",
            "Converted image to grayscale..\n",
            "Reduced noise in the image..\n",
            "Binarized the image..\n",
            "Detected skew angle: 0.00 degrees\n",
            "Corrected image orientation..\n",
            "Saved processed image to: /content/processed_images/19396040.png\n",
            "--------------------------------------------------\n",
            "Processing resume: 37335325.pdf\n",
            "Converted image to grayscale..\n",
            "Reduced noise in the image..\n",
            "Binarized the image..\n",
            "Detected skew angle: -0.00 degrees\n",
            "Corrected image orientation..\n",
            "Saved processed image to: /content/processed_images/37335325.png\n",
            "--------------------------------------------------\n",
            "Processing resume: 50328713.pdf\n",
            "Converted image to grayscale..\n",
            "Reduced noise in the image..\n",
            "Binarized the image..\n",
            "Detected skew angle: -0.00 degrees\n",
            "Corrected image orientation..\n",
            "Saved processed image to: /content/processed_images/50328713.png\n",
            "--------------------------------------------------\n",
            "Processing resume: 64755882.pdf\n",
            "Converted image to grayscale..\n",
            "Reduced noise in the image..\n",
            "Binarized the image..\n",
            "Detected skew angle: 0.00 degrees\n",
            "Corrected image orientation..\n",
            "Saved processed image to: /content/processed_images/64755882.png\n",
            "--------------------------------------------------\n",
            "Processing resume: 82125182.pdf\n",
            "Converted image to grayscale..\n",
            "Reduced noise in the image..\n",
            "Binarized the image..\n",
            "Detected skew angle: -0.06 degrees\n",
            "Corrected image orientation..\n",
            "Saved processed image to: /content/processed_images/82125182.png\n",
            "--------------------------------------------------\n",
            "Processing resume: 43752620.pdf\n",
            "Converted image to grayscale..\n",
            "Reduced noise in the image..\n",
            "Binarized the image..\n",
            "Detected skew angle: 0.00 degrees\n",
            "Corrected image orientation..\n",
            "Saved processed image to: /content/processed_images/43752620.png\n",
            "--------------------------------------------------\n",
            "Processing resume: 16803215.pdf\n",
            "Converted image to grayscale..\n",
            "Reduced noise in the image..\n",
            "Binarized the image..\n",
            "Detected skew angle: -0.00 degrees\n",
            "Corrected image orientation..\n",
            "Saved processed image to: /content/processed_images/16803215.png\n",
            "--------------------------------------------------\n",
            "Processing resume: 10624813.pdf\n",
            "Converted image to grayscale..\n",
            "Reduced noise in the image..\n",
            "Binarized the image..\n",
            "Detected skew angle: -0.07 degrees\n",
            "Corrected image orientation..\n",
            "Saved processed image to: /content/processed_images/10624813.png\n",
            "--------------------------------------------------\n",
            "Processing resume: 21298336.pdf\n",
            "Converted image to grayscale..\n",
            "Reduced noise in the image..\n",
            "Binarized the image..\n",
            "Detected skew angle: 0.00 degrees\n",
            "Corrected image orientation..\n",
            "Saved processed image to: /content/processed_images/21298336.png\n",
            "--------------------------------------------------\n",
            "Processing resume: 28078163.pdf\n",
            "Converted image to grayscale..\n",
            "Reduced noise in the image..\n",
            "Binarized the image..\n",
            "Detected skew angle: -0.04 degrees\n",
            "Corrected image orientation..\n",
            "Saved processed image to: /content/processed_images/28078163.png\n",
            "--------------------------------------------------\n",
            "Processing resume: 22890839.pdf\n",
            "Converted image to grayscale..\n",
            "Reduced noise in the image..\n",
            "Binarized the image..\n",
            "Detected skew angle: 0.00 degrees\n",
            "Corrected image orientation..\n",
            "Saved processed image to: /content/processed_images/22890839.png\n",
            "--------------------------------------------------\n",
            "Processing resume: 25930778.pdf\n",
            "Converted image to grayscale..\n",
            "Reduced noise in the image..\n",
            "Binarized the image..\n",
            "Detected skew angle: -0.00 degrees\n",
            "Corrected image orientation..\n",
            "Saved processed image to: /content/processed_images/25930778.png\n",
            "--------------------------------------------------\n",
            "Processing images is completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text extraction using Tesseract:"
      ],
      "metadata": {
        "id": "2YH7EWVPzPlu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import pytesseract\n",
        "import time\n",
        "\n",
        "input_folder_path = \"/content/processed_images\"\n",
        "output_folder_path = \"/content/tesseract_output\"\n",
        "start_time = time.time()\n",
        "\n",
        "if os.makedirs(output_folder_path, exist_ok=True):\n",
        "  print(f\"Created folder: {output_folder_path}\")\n",
        "\n",
        "total_images = sum(1 for entry in os.scandir(input_folder_path))\n",
        "print(f\"Total images in folder: {total_images}\")\n",
        "\n",
        "for i, image_name in enumerate(os.listdir(input_folder_path)[:20], 1):\n",
        "  print(f\"Processing image {i}/{total_images}: {image_name}\")\n",
        "  image_path = os.path.join(input_folder_path, image_name)\n",
        "  print(\"Extracting text from image..\")\n",
        "  text = pytesseract.image_to_string(Image.open(image_path))\n",
        "  output_path = os.path.join(output_folder_path, image_name.replace(\".png\", \".txt\"))\n",
        "  with open(output_path, \"w\") as f:\n",
        "    f.write(text)\n",
        "\n",
        "  print(f\"Saved extracted text to {output_path}\")\n",
        "  print(\"-\"*50)\n",
        "\n",
        "print(\"Text Extraction Completed.\")\n",
        "print(f\"Total time taken: {time.time() - start_time} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k68l4pDBxt4x",
        "outputId": "b0492bb1-5722-44fb-d4cd-4a4bb83a29c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total images in folder: 138\n",
            "Processing image 1/138: 21763056.png\n",
            "Extracting text from image..\n",
            "Saved extracted text to /content/tesseract_output/21763056.txt\n",
            "--------------------------------------------------\n",
            "Processing image 2/138: 29999135.png\n",
            "Extracting text from image..\n",
            "Saved extracted text to /content/tesseract_output/29999135.txt\n",
            "--------------------------------------------------\n",
            "Processing image 3/138: 25749150.png\n",
            "Extracting text from image..\n",
            "Saved extracted text to /content/tesseract_output/25749150.txt\n",
            "--------------------------------------------------\n",
            "Processing image 4/138: 27558837.png\n",
            "Extracting text from image..\n",
            "Saved extracted text to /content/tesseract_output/27558837.txt\n",
            "--------------------------------------------------\n",
            "Processing image 5/138: 27152464.png\n",
            "Extracting text from image..\n",
            "Saved extracted text to /content/tesseract_output/27152464.txt\n",
            "--------------------------------------------------\n",
            "Processing image 6/138: 25935030.png\n",
            "Extracting text from image..\n",
            "Saved extracted text to /content/tesseract_output/25935030.txt\n",
            "--------------------------------------------------\n",
            "Processing image 7/138: 20345168.png\n",
            "Extracting text from image..\n",
            "Saved extracted text to /content/tesseract_output/20345168.txt\n",
            "--------------------------------------------------\n",
            "Processing image 8/138: 25862026.png\n",
            "Extracting text from image..\n",
            "Saved extracted text to /content/tesseract_output/25862026.txt\n",
            "--------------------------------------------------\n",
            "Processing image 9/138: 80053367.png\n",
            "Extracting text from image..\n",
            "Saved extracted text to /content/tesseract_output/80053367.txt\n",
            "--------------------------------------------------\n",
            "Processing image 10/138: 25462793.png\n",
            "Extracting text from image..\n",
            "Saved extracted text to /content/tesseract_output/25462793.txt\n",
            "--------------------------------------------------\n",
            "Processing image 11/138: 28078163.png\n",
            "Extracting text from image..\n",
            "Saved extracted text to /content/tesseract_output/28078163.txt\n",
            "--------------------------------------------------\n",
            "Processing image 12/138: 82125182.png\n",
            "Extracting text from image..\n",
            "Saved extracted text to /content/tesseract_output/82125182.txt\n",
            "--------------------------------------------------\n",
            "Processing image 13/138: 18635654.png\n",
            "Extracting text from image..\n",
            "Saved extracted text to /content/tesseract_output/18635654.txt\n",
            "--------------------------------------------------\n",
            "Processing image 14/138: 34198885.png\n",
            "Extracting text from image..\n",
            "Saved extracted text to /content/tesseract_output/34198885.txt\n",
            "--------------------------------------------------\n",
            "Processing image 15/138: 17556527.png\n",
            "Extracting text from image..\n",
            "Saved extracted text to /content/tesseract_output/17556527.txt\n",
            "--------------------------------------------------\n",
            "Processing image 16/138: 17306905.png\n",
            "Extracting text from image..\n",
            "Saved extracted text to /content/tesseract_output/17306905.txt\n",
            "--------------------------------------------------\n",
            "Processing image 17/138: 20082776.png\n",
            "Extracting text from image..\n",
            "Saved extracted text to /content/tesseract_output/20082776.txt\n",
            "--------------------------------------------------\n",
            "Processing image 18/138: 25547145.png\n",
            "Extracting text from image..\n",
            "Saved extracted text to /content/tesseract_output/25547145.txt\n",
            "--------------------------------------------------\n",
            "Processing image 19/138: 37997506.png\n",
            "Extracting text from image..\n",
            "Saved extracted text to /content/tesseract_output/37997506.txt\n",
            "--------------------------------------------------\n",
            "Processing image 20/138: 39115899.png\n",
            "Extracting text from image..\n",
            "Saved extracted text to /content/tesseract_output/39115899.txt\n",
            "--------------------------------------------------\n",
            "Text Extraction Completed.\n",
            "Total time taken: 265.2858603000641 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Now that all the text is in .txt files, we can pass all the info into an LLM and extract \"information\" from our \"data\""
      ],
      "metadata": {
        "id": "zqJWrXBuz8ab"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "Extract key information from the given resume text.\n",
        "Information to be extracted: Position, skills, summary, work_experience.\n",
        "\n",
        "The text has been extracted from a resume using Tesseract OCR. Use only this text to extract information.\n",
        "Do NOT make up or generate any data. If a field is not present in the text, leave it as a blank string (\"\").\n",
        "\n",
        "For the \"work_experience\" field, summarize the person's experience into a short paragraph highlighting their key roles, achievements, and duration, based only on the extracted text.\n",
        "\n",
        "Always give your response in the following JSON format:\n",
        "\n",
        "{\n",
        "    \"Position\": \"\",\n",
        "    \"skills\": \"\",\n",
        "    \"summary\": \"\",\n",
        "    \"work_experience\": \"\"\n",
        "}\n",
        "\n",
        "Respond strictly in the specified JSON format without adding any extra commentary or explanation.\n",
        "\n",
        "Here is the extracted text:\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "tLtC-yKFz7Jy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "from google.colab import userdata\n",
        "from PIL import Image\n",
        "import json\n",
        "import time\n",
        "\n",
        "genai_client = genai.Client(api_key=userdata.get('GOOGLE_API_KEY'))"
      ],
      "metadata": {
        "id": "u8RX6D1Y012d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import json\n",
        "from PIL import Image\n",
        "\n",
        "image_folder_path = \"/content/processed_images\"\n",
        "text_folder_path = \"/content/tesseract_output\"\n",
        "output_folder_path = \"/content/json_output\"\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "os.makedirs(output_folder_path, exist_ok=True)\n",
        "print(f\"Ensured folder exists: {output_folder_path}\")\n",
        "\n",
        "total_images = sum(1 for entry in os.scandir(image_folder_path))\n",
        "print(f\"Total images in folder: {total_images}\")\n",
        "\n",
        "for i, image_name in enumerate(os.listdir(image_folder_path)[:20], 1):\n",
        "    print(f\"Processing image {i}/{total_images}: {image_name}\")\n",
        "    image_path = os.path.join(image_folder_path, image_name)\n",
        "    print(f\"Loading image: {image_path}\")\n",
        "\n",
        "    with open(image_path, \"rb\") as f:\n",
        "        image = Image.open(image_path)\n",
        "\n",
        "    # Handle both .png and .jpg\n",
        "    base_name, _ = os.path.splitext(image_name)\n",
        "    text_path = os.path.join(text_folder_path, base_name + \".txt\")\n",
        "\n",
        "    print(f\"Loading extracted text: {text_path}\")\n",
        "    with open(text_path, \"r\") as f:\n",
        "        text = f.read()\n",
        "\n",
        "    print(\"Extracting information from image and text..\")\n",
        "\n",
        "    prompt_with_text = prompt + text\n",
        "\n",
        "    contents = [\n",
        "        image,\n",
        "        {\"text\": prompt_with_text}\n",
        "    ]\n",
        "    response = genai_client.models.generate_content(\n",
        "        model='gemini-2.5-flash',\n",
        "        contents=contents\n",
        "    )\n",
        "\n",
        "    # Access the usage_metadata attribute\n",
        "    usage_metadata = response.usage_metadata\n",
        "    print(f\"Input Token Count: {usage_metadata.prompt_token_count}\")\n",
        "    print(f\"Thoughts Token Count: {response.usage_metadata.thoughts_token_count}\")\n",
        "    print(f\"Output Token Count: {usage_metadata.candidates_token_count}\")\n",
        "    print(f\"Total Token Count: {usage_metadata.total_token_count}\")\n",
        "\n",
        "    # ---- Safe response parsing ----\n",
        "    response_text = None\n",
        "    if hasattr(response, \"text\") and response.text:\n",
        "        response_text = response.text\n",
        "    elif hasattr(response, \"candidates\") and response.candidates:\n",
        "        parts = response.candidates[0].content.parts\n",
        "        if parts and hasattr(parts[0], \"text\"):\n",
        "            response_text = parts[0].text\n",
        "\n",
        "    if response_text is None:\n",
        "        print(\"⚠️ No text returned from model. Skipping this file.\")\n",
        "        continue\n",
        "\n",
        "    # Clean and parse JSON safely\n",
        "    response_text = response_text.replace('```json', '').replace('```', '')\n",
        "\n",
        "    try:\n",
        "        extracted_information = json.loads(response_text)\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"⚠️ Failed to decode JSON for {image_name}: {e}\")\n",
        "        continue\n",
        "\n",
        "    # Save JSON with correct name\n",
        "    output_path = os.path.join(output_folder_path, base_name + \".json\")\n",
        "    with open(output_path, \"w\") as f:\n",
        "        json.dump(extracted_information, f, indent=4)\n",
        "\n",
        "    print(f\"Saved extracted information to {output_path}\")\n",
        "    print(\"-\" * 50)\n",
        "    time.sleep(60)\n",
        "\n",
        "print(\"Information Extraction Completed.\")\n",
        "print(f\"Total time taken: {time.time() - start_time} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35xRRKT-088H",
        "outputId": "f897493e-a99b-487f-ad13-2791ff4d0a55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ensured folder exists: /content/json_output\n",
            "Total images in folder: 138\n",
            "Processing image 1/138: 21763056.png\n",
            "Loading image: /content/processed_images/21763056.png\n",
            "Loading extracted text: /content/tesseract_output/21763056.txt\n",
            "Extracting information from image and text..\n",
            "Input Token Count: 1247\n",
            "Thoughts Token Count: 1722\n",
            "Output Token Count: 368\n",
            "Total Token Count: 3337\n",
            "Saved extracted information to /content/json_output/21763056.json\n",
            "--------------------------------------------------\n",
            "Processing image 2/138: 29999135.png\n",
            "Loading image: /content/processed_images/29999135.png\n",
            "Loading extracted text: /content/tesseract_output/29999135.txt\n",
            "Extracting information from image and text..\n",
            "Input Token Count: 1327\n",
            "Thoughts Token Count: 2063\n",
            "Output Token Count: 390\n",
            "Total Token Count: 3780\n",
            "Saved extracted information to /content/json_output/29999135.json\n",
            "--------------------------------------------------\n",
            "Processing image 3/138: 25749150.png\n",
            "Loading image: /content/processed_images/25749150.png\n",
            "Loading extracted text: /content/tesseract_output/25749150.txt\n",
            "Extracting information from image and text..\n",
            "Input Token Count: 1406\n",
            "Thoughts Token Count: 715\n",
            "Output Token Count: 384\n",
            "Total Token Count: 2505\n",
            "Saved extracted information to /content/json_output/25749150.json\n",
            "--------------------------------------------------\n",
            "Processing image 4/138: 27558837.png\n",
            "Loading image: /content/processed_images/27558837.png\n",
            "Loading extracted text: /content/tesseract_output/27558837.txt\n",
            "Extracting information from image and text..\n",
            "Input Token Count: 1499\n",
            "Thoughts Token Count: 2103\n",
            "Output Token Count: 298\n",
            "Total Token Count: 3900\n",
            "Saved extracted information to /content/json_output/27558837.json\n",
            "--------------------------------------------------\n",
            "Processing image 5/138: 27152464.png\n",
            "Loading image: /content/processed_images/27152464.png\n",
            "Loading extracted text: /content/tesseract_output/27152464.txt\n",
            "Extracting information from image and text..\n",
            "Input Token Count: 1397\n",
            "Thoughts Token Count: None\n",
            "Output Token Count: 1815\n",
            "Total Token Count: 3212\n",
            "⚠️ Failed to decode JSON for 27152464.png: Expecting value: line 1 column 1 (char 0)\n",
            "Processing image 6/138: 25935030.png\n",
            "Loading image: /content/processed_images/25935030.png\n",
            "Loading extracted text: /content/tesseract_output/25935030.txt\n",
            "Extracting information from image and text..\n",
            "Input Token Count: 1045\n",
            "Thoughts Token Count: 1934\n",
            "Output Token Count: 323\n",
            "Total Token Count: 3302\n",
            "Saved extracted information to /content/json_output/25935030.json\n",
            "--------------------------------------------------\n",
            "Processing image 7/138: 20345168.png\n",
            "Loading image: /content/processed_images/20345168.png\n",
            "Loading extracted text: /content/tesseract_output/20345168.txt\n",
            "Extracting information from image and text..\n",
            "Input Token Count: 1210\n",
            "Thoughts Token Count: 1594\n",
            "Output Token Count: 274\n",
            "Total Token Count: 3078\n",
            "Saved extracted information to /content/json_output/20345168.json\n",
            "--------------------------------------------------\n",
            "Processing image 8/138: 25862026.png\n",
            "Loading image: /content/processed_images/25862026.png\n",
            "Loading extracted text: /content/tesseract_output/25862026.txt\n",
            "Extracting information from image and text..\n",
            "Input Token Count: 1575\n",
            "Thoughts Token Count: 753\n",
            "Output Token Count: 424\n",
            "Total Token Count: 2752\n",
            "Saved extracted information to /content/json_output/25862026.json\n",
            "--------------------------------------------------\n",
            "Processing image 9/138: 80053367.png\n",
            "Loading image: /content/processed_images/80053367.png\n",
            "Loading extracted text: /content/tesseract_output/80053367.txt\n",
            "Extracting information from image and text..\n",
            "Input Token Count: 1193\n",
            "Thoughts Token Count: 193\n",
            "Output Token Count: 503\n",
            "Total Token Count: 1889\n",
            "Saved extracted information to /content/json_output/80053367.json\n",
            "--------------------------------------------------\n",
            "Processing image 10/138: 25462793.png\n",
            "Loading image: /content/processed_images/25462793.png\n",
            "Loading extracted text: /content/tesseract_output/25462793.txt\n",
            "Extracting information from image and text..\n",
            "Input Token Count: 1151\n",
            "Thoughts Token Count: 878\n",
            "Output Token Count: 391\n",
            "Total Token Count: 2420\n",
            "Saved extracted information to /content/json_output/25462793.json\n",
            "--------------------------------------------------\n",
            "Processing image 11/138: 28078163.png\n",
            "Loading image: /content/processed_images/28078163.png\n",
            "Loading extracted text: /content/tesseract_output/28078163.txt\n",
            "Extracting information from image and text..\n",
            "Input Token Count: 1523\n",
            "Thoughts Token Count: 2464\n",
            "Output Token Count: 351\n",
            "Total Token Count: 4338\n",
            "Saved extracted information to /content/json_output/28078163.json\n",
            "--------------------------------------------------\n",
            "Processing image 12/138: 82125182.png\n",
            "Loading image: /content/processed_images/82125182.png\n",
            "Loading extracted text: /content/tesseract_output/82125182.txt\n",
            "Extracting information from image and text..\n",
            "Input Token Count: 1251\n",
            "Thoughts Token Count: 2548\n",
            "Output Token Count: 474\n",
            "Total Token Count: 4273\n",
            "Saved extracted information to /content/json_output/82125182.json\n",
            "--------------------------------------------------\n",
            "Processing image 13/138: 18635654.png\n",
            "Loading image: /content/processed_images/18635654.png\n",
            "Loading extracted text: /content/tesseract_output/18635654.txt\n",
            "Extracting information from image and text..\n",
            "Input Token Count: 1211\n",
            "Thoughts Token Count: 1644\n",
            "Output Token Count: 333\n",
            "Total Token Count: 3188\n",
            "Saved extracted information to /content/json_output/18635654.json\n",
            "--------------------------------------------------\n",
            "Processing image 14/138: 34198885.png\n",
            "Loading image: /content/processed_images/34198885.png\n",
            "Loading extracted text: /content/tesseract_output/34198885.txt\n",
            "Extracting information from image and text..\n",
            "Input Token Count: 1491\n",
            "Thoughts Token Count: 659\n",
            "Output Token Count: 388\n",
            "Total Token Count: 2538\n",
            "Saved extracted information to /content/json_output/34198885.json\n",
            "--------------------------------------------------\n",
            "Processing image 15/138: 17556527.png\n",
            "Loading image: /content/processed_images/17556527.png\n",
            "Loading extracted text: /content/tesseract_output/17556527.txt\n",
            "Extracting information from image and text..\n",
            "Input Token Count: 1525\n",
            "Thoughts Token Count: 1951\n",
            "Output Token Count: 406\n",
            "Total Token Count: 3882\n",
            "Saved extracted information to /content/json_output/17556527.json\n",
            "--------------------------------------------------\n",
            "Processing image 16/138: 17306905.png\n",
            "Loading image: /content/processed_images/17306905.png\n",
            "Loading extracted text: /content/tesseract_output/17306905.txt\n",
            "Extracting information from image and text..\n",
            "Input Token Count: 909\n",
            "Thoughts Token Count: 1547\n",
            "Output Token Count: 457\n",
            "Total Token Count: 2913\n",
            "Saved extracted information to /content/json_output/17306905.json\n",
            "--------------------------------------------------\n",
            "Processing image 17/138: 20082776.png\n",
            "Loading image: /content/processed_images/20082776.png\n",
            "Loading extracted text: /content/tesseract_output/20082776.txt\n",
            "Extracting information from image and text..\n",
            "Input Token Count: 1318\n",
            "Thoughts Token Count: 4541\n",
            "Output Token Count: 764\n",
            "Total Token Count: 6623\n",
            "Saved extracted information to /content/json_output/20082776.json\n",
            "--------------------------------------------------\n",
            "Processing image 18/138: 25547145.png\n",
            "Loading image: /content/processed_images/25547145.png\n",
            "Loading extracted text: /content/tesseract_output/25547145.txt\n",
            "Extracting information from image and text..\n",
            "Input Token Count: 1291\n",
            "Thoughts Token Count: 413\n",
            "Output Token Count: 425\n",
            "Total Token Count: 2129\n",
            "Saved extracted information to /content/json_output/25547145.json\n",
            "--------------------------------------------------\n",
            "Processing image 19/138: 37997506.png\n",
            "Loading image: /content/processed_images/37997506.png\n",
            "Loading extracted text: /content/tesseract_output/37997506.txt\n",
            "Extracting information from image and text..\n",
            "Input Token Count: 1376\n",
            "Thoughts Token Count: 1237\n",
            "Output Token Count: 378\n",
            "Total Token Count: 2991\n",
            "Saved extracted information to /content/json_output/37997506.json\n",
            "--------------------------------------------------\n",
            "Processing image 20/138: 39115899.png\n",
            "Loading image: /content/processed_images/39115899.png\n",
            "Loading extracted text: /content/tesseract_output/39115899.txt\n",
            "Extracting information from image and text..\n",
            "Input Token Count: 1306\n",
            "Thoughts Token Count: 1123\n",
            "Output Token Count: 245\n",
            "Total Token Count: 2674\n",
            "Saved extracted information to /content/json_output/39115899.json\n",
            "--------------------------------------------------\n",
            "Information Extraction Completed.\n",
            "Total time taken: 1480.0214381217957 seconds\n"
          ]
        }
      ]
    }
  ]
}